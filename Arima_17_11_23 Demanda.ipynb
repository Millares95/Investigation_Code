{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\milla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing Basic libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os \n",
    "import re\n",
    "# Importing time series specific libraries\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy.stats import bartlett\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.statespace import sarimax\n",
    "import prophet\n",
    "from prophet import Prophet\n",
    "from scipy.stats import levene\n",
    "# Miscellaneous libararies\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from math import sqrt\n",
    "from random import random\n",
    "\n",
    "# Libaraies for evaluation of model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error, mean_squared_log_error\n",
    "from statsmodels.tsa.arima.model import ARIMAResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     idprov      fecha  dem1  dem2  dem3  dem4  dem5  dem6  dem7  dem8  ...  \\\n",
      "0       IJV 2007-05-01   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "1       IJV 2007-07-01   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "2       IJV 2007-07-27   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "3       IJV 2007-07-28   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "4       IJV 2007-07-30   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "...     ...        ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "3915    IJV 2018-04-14  15.0  14.0  13.0  13.0  13.0  13.0  13.0  12.0  ...   \n",
      "3916    IJV 2018-04-15  15.0  14.0  14.0  13.0  13.0  13.0  12.0  12.0  ...   \n",
      "3917    IJV 2018-04-16  14.0  13.0  13.0  13.0  12.0  13.0  12.0  12.0  ...   \n",
      "3918    IJV 2018-04-17  11.0  11.0  10.0  10.0  10.0  10.0  10.0  10.0  ...   \n",
      "3919    IJV 2018-04-18  12.0  11.0  11.0  10.0  10.0  11.0  11.0  11.0  ...   \n",
      "\n",
      "      dem16  dem17  dem18  dem19  dem20  dem21  dem22  dem23  dem24  dem25  \n",
      "0       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "1       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "2       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "3       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "4       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "3915   12.0   12.0   13.0   14.0   15.0   16.0   16.0   16.0   15.0   16.0  \n",
      "3916   12.0   12.0   13.0   14.0   15.0   15.0   16.0   16.0   15.0   16.0  \n",
      "3917   12.0   12.0   12.0   12.0   14.0   14.0   14.0   13.0   12.0   14.0  \n",
      "3918   11.0   11.0   12.0   13.0   14.0   14.0   14.0   13.0   12.0   14.0  \n",
      "3919   13.0   12.0   13.0   13.0   14.0   15.0   15.0   14.0   13.0   15.0  \n",
      "\n",
      "[3920 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "#TODO Cargar los datos de la hoja de calculo en el archivo \"load_IJV.xlsx\"\n",
    "# Obtener la ruta absoluta del script de Python\n",
    "def importar_datos(x):\n",
    "    global df\n",
    "    ruta_script = os.getcwd()\n",
    "    #Nombre del archivo de Excel a cargar\n",
    "    nombre_archivo = x\n",
    "    # Combinar la ruta del script y el nombre del archivo\n",
    "    ruta_archivo = os.path.join(ruta_script, nombre_archivo)\n",
    "    # Cargar los datos del archivo de Excel en un DataFrame de pandas\n",
    "    df = pd.read_excel(ruta_archivo)\n",
    "    # Imprimir el df \n",
    "    return df\n",
    "importar_datos('load_IJV.xlsx')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     idprov      fecha  dem1  dem2  dem3  dem4  dem5  dem6  dem7  dem8  ...  \\\n",
      "159     IJV 2008-01-01   9.0   9.0   8.0   8.0   8.0   9.0   9.0  10.0  ...   \n",
      "160     IJV 2008-01-02   8.0   6.0   8.0   7.0   8.0   8.0   8.0  10.0  ...   \n",
      "161     IJV 2008-01-03   6.0   4.0   5.0   6.0   6.0   5.0  10.0  10.0  ...   \n",
      "162     IJV 2008-01-04   6.0   6.0   7.0   6.0   6.0   8.0  10.0  11.0  ...   \n",
      "163     IJV 2008-01-05   6.0   6.0   6.0   6.0   6.0   8.0   9.0  10.0  ...   \n",
      "...     ...        ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "3807    IJV 2017-12-27  10.0  10.0   9.0   9.0  10.0  10.0  11.0  12.0  ...   \n",
      "3808    IJV 2017-12-28  10.0  10.0  10.0   9.0  10.0  10.0  11.0  12.0  ...   \n",
      "3809    IJV 2017-12-29  11.0  10.0  10.0  10.0  10.0  10.0  11.0  11.0  ...   \n",
      "3810    IJV 2017-12-30  11.0  11.0  10.0  10.0  10.0  10.0  11.0  11.0  ...   \n",
      "3811    IJV 2017-12-31  11.0  10.0  10.0  10.0   9.0  10.0  10.0  11.0  ...   \n",
      "\n",
      "      dem16  dem17  dem18  dem19  dem20  dem21  dem22  dem23  dem24  dem25  \n",
      "159    11.0   12.0   14.0   15.0   12.0   11.0   11.0   10.0   10.0   16.0  \n",
      "160    12.0   15.0   17.0   16.0   11.0    9.0    8.0    7.0    6.0   17.0  \n",
      "161    11.0   15.0   18.0   17.0   12.0   10.0    9.0    7.0    7.0   19.0  \n",
      "162    12.0   14.0   18.0   19.0   13.0   10.0    9.0    7.0    7.0   19.0  \n",
      "163    12.0   11.0   18.0   19.0   14.0   11.0   10.0    8.0    8.0   20.0  \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "3807   12.0   12.0   13.0   16.0   14.0   13.0   12.0   12.0   11.0   16.0  \n",
      "3808   12.0   12.0   15.0   16.0   14.0   13.0   13.0   12.0   11.0   16.0  \n",
      "3809   12.0   13.0   14.0   16.0   14.0   13.0   13.0   12.0   12.0   16.0  \n",
      "3810   11.0   12.0   14.0   15.0   14.0   12.0   12.0   12.0   11.0   15.0  \n",
      "3811   11.0   11.0   12.0   13.0   11.0   10.0   10.0   10.0    9.0   13.0  \n",
      "\n",
      "[3653 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# #Identificar los valores Ãºnicos en la columna \"idprov\"\n",
    "# idprov_unique = df[\"idprov\"].unique()\n",
    "\n",
    "# # Verificar si hay valores diferentes a \"IJV\"\n",
    "# if len(idprov_unique) > 1 or idprov_unique[0] != \"'IJV'\":\n",
    "#     # Mostrar los valores diferentes a \"IJV\"\n",
    "#     print(\"Los siguientes valores no son 'IJV':\")\n",
    "#     print(df.loc[df[\"idprov\"] != \"IJV\"])\n",
    "# else:\n",
    "#     # Todos los valores de la columna \"idprov\" son \"IJV\"\n",
    "#     print(\"Todos los valores de la columna 'idprov' son 'IJV'\")\n",
    "#     # Eliminar la columna \"idprov\" del DataFrame\n",
    "#     df = df.drop(\"idprov\", axis=1)\n",
    "# print(df)\n",
    "df = df[df['fecha'] >= '2008-01-01']\n",
    "df = df[df['fecha'] <= '2017-12-31']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     idprov      fecha  dem1  dem2  dem3  dem4  dem5  dem6  dem7  dem8  ...  \\\n",
      "159     IJV 2008-01-01   9.0   9.0   8.0   8.0   8.0   9.0   9.0  10.0  ...   \n",
      "160     IJV 2008-01-02   8.0   6.0   8.0   7.0   8.0   8.0   8.0  10.0  ...   \n",
      "161     IJV 2008-01-03   6.0   4.0   5.0   6.0   6.0   5.0  10.0  10.0  ...   \n",
      "162     IJV 2008-01-04   6.0   6.0   7.0   6.0   6.0   8.0  10.0  11.0  ...   \n",
      "163     IJV 2008-01-05   6.0   6.0   6.0   6.0   6.0   8.0   9.0  10.0  ...   \n",
      "...     ...        ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "3807    IJV 2017-12-27  10.0  10.0   9.0   9.0  10.0  10.0  11.0  12.0  ...   \n",
      "3808    IJV 2017-12-28  10.0  10.0  10.0   9.0  10.0  10.0  11.0  12.0  ...   \n",
      "3809    IJV 2017-12-29  11.0  10.0  10.0  10.0  10.0  10.0  11.0  11.0  ...   \n",
      "3810    IJV 2017-12-30  11.0  11.0  10.0  10.0  10.0  10.0  11.0  11.0  ...   \n",
      "3811    IJV 2017-12-31  11.0  10.0  10.0  10.0   9.0  10.0  10.0  11.0  ...   \n",
      "\n",
      "      dem15  dem16  dem17  dem18  dem19  dem20  dem21  dem22  dem23  dem24  \n",
      "159    11.0   11.0   12.0   14.0   15.0   12.0   11.0   11.0   10.0   10.0  \n",
      "160     8.0   12.0   15.0   17.0   16.0   11.0    9.0    8.0    7.0    6.0  \n",
      "161    11.0   11.0   15.0   18.0   17.0   12.0   10.0    9.0    7.0    7.0  \n",
      "162    11.0   12.0   14.0   18.0   19.0   13.0   10.0    9.0    7.0    7.0  \n",
      "163    11.0   12.0   11.0   18.0   19.0   14.0   11.0   10.0    8.0    8.0  \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "3807   12.0   12.0   12.0   13.0   16.0   14.0   13.0   12.0   12.0   11.0  \n",
      "3808   12.0   12.0   12.0   15.0   16.0   14.0   13.0   13.0   12.0   11.0  \n",
      "3809   12.0   12.0   13.0   14.0   16.0   14.0   13.0   13.0   12.0   12.0  \n",
      "3810   11.0   11.0   12.0   14.0   15.0   14.0   12.0   12.0   12.0   11.0  \n",
      "3811   11.0   11.0   11.0   12.0   13.0   11.0   10.0   10.0   10.0    9.0  \n",
      "\n",
      "[3653 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# eliminar la columna 25 porque me da el maximo valor solamente \n",
    "df = df.drop('dem25', axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  idprov      fecha  dem1  dem2  dem3  dem4  dem5  dem6  dem7  dem8  ...  \\\n",
      "1    IJV 2008-01-01   9.0   9.0   8.0   8.0   8.0   9.0   9.0  10.0  ...   \n",
      "2    IJV 2008-01-02   8.0   6.0   8.0   7.0   8.0   8.0   8.0  10.0  ...   \n",
      "3    IJV 2008-01-03   6.0   4.0   5.0   6.0   6.0   5.0  10.0  10.0  ...   \n",
      "4    IJV 2008-01-04   6.0   6.0   7.0   6.0   6.0   8.0  10.0  11.0  ...   \n",
      "5    IJV 2008-01-05   6.0   6.0   6.0   6.0   6.0   8.0   9.0  10.0  ...   \n",
      "\n",
      "   dem15  dem16  dem17  dem18  dem19  dem20  dem21  dem22  dem23  dem24  \n",
      "1   11.0   11.0   12.0   14.0   15.0   12.0   11.0   11.0   10.0   10.0  \n",
      "2    8.0   12.0   15.0   17.0   16.0   11.0    9.0    8.0    7.0    6.0  \n",
      "3   11.0   11.0   15.0   18.0   17.0   12.0   10.0    9.0    7.0    7.0  \n",
      "4   11.0   12.0   14.0   18.0   19.0   13.0   10.0    9.0    7.0    7.0  \n",
      "5   11.0   12.0   11.0   18.0   19.0   14.0   11.0   10.0    8.0    8.0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#  #convertir la columna 'fecha' a formato de fecha y hora\n",
    "# df['fecha'] = pd.to_datetime(df['fecha'], format=\"'%d-%b-%Y %H:%M:%S'\")\n",
    "# # convertir la columna 'fecha' a formato de fecha y hora\n",
    "# df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "# # establecer la columna 'fecha' como el Ã­ndice del DataFrame\n",
    "# df = df.set_index('fecha')\n",
    "# # utilizar resample con una frecuencia de 1 hora para agregar una fila por cada hora del dÃ­a\n",
    "# df_resampled = df.resample('1H').asfreq()\n",
    "# display(df_resampled)\n",
    "# restaring the index\n",
    "df.index = np.arange(1, len(df) + 1, 1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengthBefore = 3653\n",
      "[60, 1521, 2982]\n",
      "lengthAfter = 3650\n"
     ]
    }
   ],
   "source": [
    "# def sort_columns(col):\n",
    "#     return int(re.findall(r'\\d+', col)[0])\n",
    "\n",
    "# # ordenar las columnas de demanda por su nÃºmero\n",
    "# cols_dem = sorted([col for col in df_resampled.columns if 'dem' in col], key=sort_columns)\n",
    "\n",
    "\n",
    "# # apilar las columnas de demanda en una sola columna\n",
    "# df_melted = df_resampled[cols_dem].reset_index().melt(id_vars='fecha', var_name='hora', value_name='demanda')\n",
    "\n",
    "# # eliminar las filas con NaN en la columna de demanda\n",
    "# df_clean = df_melted.dropna(subset=['demanda'])\n",
    "\n",
    "# # convertir la columna hora en una categorÃ­a ordenada\n",
    "# df_clean['hora'] = pd.Categorical(df_clean['hora'], categories=[f'dem{i}' for i in range(0,25)], ordered=True)\n",
    "\n",
    "\n",
    "# # ordenar el DataFrame por fecha y hora\n",
    "# df_final = df_clean.sort_values(['fecha', 'hora'])\n",
    "\n",
    "\n",
    "\n",
    "# # resetear el Ã­ndice del DataFrame\n",
    "# df_final = df_final.reset_index(drop=True)\n",
    "\n",
    "# df_final = df_final.drop('hora', axis=1)\n",
    "\n",
    "# #TODO ponerle hora a cada una de las fechas -------------------------------------------------------------------------------------\n",
    "# # convertir la columna fecha en un objeto datetime\n",
    "# df_final['fecha'] = pd.to_datetime(df_final['fecha'], format='%d-%b-%Y %H:%M:%S')\n",
    "\n",
    "# last_day = None\n",
    "# # Organizar el datatime para agregarle una hora a cada datatime cada 24 horas\n",
    "# for i in range(len(df_final)):\n",
    "#     # Verificar si se debe reiniciar la suma\n",
    "#     if last_day is None or df_final.loc[i, 'fecha'].day != last_day:\n",
    "#         last_day = df_final.loc[i, 'fecha'].day\n",
    "#         hours_to_add = 1\n",
    "#     else:\n",
    "#         hours_to_add += 1\n",
    "        \n",
    "#     # Agregar la cantidad de horas correspondiente\n",
    "#     df_final.loc[i, 'fecha'] += pd.DateOffset(hours=hours_to_add)\n",
    "\n",
    "# display( df_final) \n",
    "# removing February 29\n",
    "print(\"lengthBefore =\", len(df)) # checking\n",
    "idx_1 = df[df[\"fecha\"] == '2008-02-29']\n",
    "idx_2 = df[df[\"fecha\"] == '2012-02-29']\n",
    "idx_3 = df[df[\"fecha\"] == '2016-02-29']\n",
    "toRemove = [idx_1.index.item(), idx_2.index.item(), idx_3.index.item()]\n",
    "print(toRemove)\n",
    "df = df.drop(toRemove)\n",
    "print(\"lengthAfter =\", len(df)) # checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     idprov      fecha  dem1  dem2  dem3  dem4  dem5  dem6  dem7  dem8  ...  \\\n",
      "1       IJV 2008-01-01   9.0   9.0   8.0   8.0   8.0   9.0   9.0  10.0  ...   \n",
      "367     IJV 2009-01-01   8.0   8.0   8.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "732     IJV 2010-01-01   8.0   7.0   7.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "1097    IJV 2011-01-01   7.0   6.0   6.0   6.0   6.0   6.0   6.0   8.0  ...   \n",
      "1462    IJV 2012-01-01   8.0   7.0   6.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "1828    IJV 2013-01-01   8.0   8.0   8.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "2193    IJV 2014-01-01  11.0  10.0  10.0  10.0   9.0  10.0  10.0  10.0  ...   \n",
      "2558    IJV 2015-01-01  10.0  10.0   9.0   9.0   9.0   9.0   9.0  10.0  ...   \n",
      "2923    IJV 2016-01-01  12.0  12.0  11.0  11.0  11.0  11.0  10.0  11.0  ...   \n",
      "3289    IJV 2017-01-01  10.0  10.0  10.0   9.0   9.0   9.0   9.0  10.0  ...   \n",
      "\n",
      "      dem15  dem16  dem17  dem18  dem19  dem20  dem21  dem22  dem23  dem24  \n",
      "1      11.0   11.0   12.0   14.0   15.0   12.0   11.0   11.0   10.0   10.0  \n",
      "367     9.0   10.0   11.0   13.0   13.0   11.0   10.0    9.0    8.0    8.0  \n",
      "732     9.0    9.0   11.0   12.0   14.0   12.0   10.0    9.0    8.0    8.0  \n",
      "1097    9.0    9.0   10.0   13.0   13.0   11.0    9.0    8.0    8.0    7.0  \n",
      "1462    9.0    9.0   10.0   13.0   14.0   11.0   10.0    9.0    8.0    8.0  \n",
      "1828    9.0    9.0   11.0   13.0   14.0   12.0   10.0   10.0    9.0    8.0  \n",
      "2193    9.0   10.0   11.0   13.0   14.0   13.0   12.0   12.0   11.0   10.0  \n",
      "2558    9.0   10.0   11.0   10.0   14.0   12.0   12.0   11.0   11.0   10.0  \n",
      "2923   11.0   11.0   11.0   13.0   14.0   13.0   13.0   13.0   12.0   11.0  \n",
      "3289   10.0   10.0   11.0   12.0   14.0   12.0   12.0   12.0   12.0   11.0  \n",
      "\n",
      "[10 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# # Seleccionar las filas que no tienen fechas del 29 de febrero\n",
    "# df_final = df_final.loc[(df_final['fecha'].dt.day != 29) | (df_final['fecha'].dt.month != 2)]\n",
    "\n",
    "# # Imprimir el nuevo DataFrame sin las filas del 29 de febrero\n",
    "# print(df_final)\n",
    "# filtering data needed\n",
    "dfFiltered = df[df['fecha'].dt.strftime('%m-%d') == '01-01']\n",
    "print(dfFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   idprov      fecha  dem1  dem2  dem3  dem4  dem5  dem6  dem7  dem8  ...  \\\n",
      "1     IJV 2008-01-01   9.0   9.0   8.0   8.0   8.0   9.0   9.0  10.0  ...   \n",
      "2     IJV 2009-01-01   8.0   8.0   8.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "3     IJV 2010-01-01   8.0   7.0   7.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "4     IJV 2011-01-01   7.0   6.0   6.0   6.0   6.0   6.0   6.0   8.0  ...   \n",
      "5     IJV 2012-01-01   8.0   7.0   6.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "6     IJV 2013-01-01   8.0   8.0   8.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "7     IJV 2014-01-01  11.0  10.0  10.0  10.0   9.0  10.0  10.0  10.0  ...   \n",
      "8     IJV 2015-01-01  10.0  10.0   9.0   9.0   9.0   9.0   9.0  10.0  ...   \n",
      "9     IJV 2016-01-01  12.0  12.0  11.0  11.0  11.0  11.0  10.0  11.0  ...   \n",
      "10    IJV 2017-01-01  10.0  10.0  10.0   9.0   9.0   9.0   9.0  10.0  ...   \n",
      "\n",
      "    dem15  dem16  dem17  dem18  dem19  dem20  dem21  dem22  dem23  dem24  \n",
      "1    11.0   11.0   12.0   14.0   15.0   12.0   11.0   11.0   10.0   10.0  \n",
      "2     9.0   10.0   11.0   13.0   13.0   11.0   10.0    9.0    8.0    8.0  \n",
      "3     9.0    9.0   11.0   12.0   14.0   12.0   10.0    9.0    8.0    8.0  \n",
      "4     9.0    9.0   10.0   13.0   13.0   11.0    9.0    8.0    8.0    7.0  \n",
      "5     9.0    9.0   10.0   13.0   14.0   11.0   10.0    9.0    8.0    8.0  \n",
      "6     9.0    9.0   11.0   13.0   14.0   12.0   10.0   10.0    9.0    8.0  \n",
      "7     9.0   10.0   11.0   13.0   14.0   13.0   12.0   12.0   11.0   10.0  \n",
      "8     9.0   10.0   11.0   10.0   14.0   12.0   12.0   11.0   11.0   10.0  \n",
      "9    11.0   11.0   11.0   13.0   14.0   13.0   13.0   13.0   12.0   11.0  \n",
      "10   10.0   10.0   11.0   12.0   14.0   12.0   12.0   12.0   12.0   11.0  \n",
      "\n",
      "[10 rows x 26 columns]\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "[ 9.  9.  8.  8.  8.  9.  9. 10. 11. 12. 12. 12. 11. 10. 11. 11. 12. 14.\n",
      " 15. 12. 11. 11. 10. 10.  8.  8.  8.  7.  7.  7.  7.  8. 10. 10. 10. 11.\n",
      " 10.  9.  9. 10. 11. 13. 13. 11. 10.  9.  8.  8.  8.  7.  7.  7.  7.  7.\n",
      "  7.  8.  9.  9. 10. 10.  9.  9.  9.  9. 11. 12. 14. 12. 10.  9.  8.  8.\n",
      "  7.  6.  6.  6.  6.  6.  6.  8.  9. 10. 10. 10.  9.  8.  9.  9. 10. 13.\n",
      " 13. 11.  9.  8.  8.  7.  8.  7.  6.  7.  7.  7.  7.  8.  9.  9. 10. 10.\n",
      "  9.  9.  9.  9. 10. 13. 14. 11. 10.  9.  8.  8.  8.  8.  8.  7.  7.  7.\n",
      "  7.  8.  9. 10. 10. 10. 10.  9.  9.  9. 11. 13. 14. 12. 10. 10.  9.  8.\n",
      " 11. 10. 10. 10.  9. 10. 10. 10. 10. 10. 11. 11. 10. 10.  9. 10. 11. 13.\n",
      " 14. 13. 12. 12. 11. 10. 10. 10.  9.  9.  9.  9.  9. 10. 10. 10. 10. 10.\n",
      " 10.  9.  9. 10. 11. 10. 14. 12. 12. 11. 11. 10. 12. 12. 11. 11. 11. 11.\n",
      " 10. 11. 12. 12. 12. 12. 11. 11. 11. 11. 11. 13. 14. 13. 13. 13. 12. 11.\n",
      " 10. 10. 10.  9.  9.  9.  9. 10. 10. 10. 11. 11. 11.  9. 10. 10. 11. 12.\n",
      " 14. 12. 12. 12. 12. 11.]\n"
     ]
    }
   ],
   "source": [
    "# # TODO calcular los valores atipicos de los datos a partir del cÃ¡lculo basado en el rango intercuartÃ­lico (RIQ)\n",
    "df_final = dfFiltered\n",
    "# restaring the index\n",
    "df_final.index = np.arange(1, len(df_final) + 1, 1)\n",
    "print(df_final)\n",
    "\n",
    "# reshape the data\n",
    "dataToFit = []\n",
    "for k in range(1, 11):\n",
    "    print(k)\n",
    "    data = df_final.loc[k,['dem1', 'dem2', 'dem3', 'dem4', 'dem5', 'dem6', 'dem7', 'dem8', 'dem9', 'dem10', 'dem11', 'dem12', 'dem13', 'dem14', 'dem15', 'dem16', 'dem17', 'dem18', 'dem19', 'dem20', 'dem21', 'dem22', 'dem23', 'dem24']]\n",
    "    data = np.array(data)    \n",
    "    dataToFit.append(data)\n",
    "    \n",
    "    #Calcula el rango intercuartÃ­lico (RIQ):\n",
    "Q1 = np.percentile(dataToFit, 25)\n",
    "Q3 = np.percentile(dataToFit, 75)\n",
    "RIQ = Q3 - Q1\n",
    "\n",
    "#Define los lÃ­mites inferior y superior para detectar outliers:\n",
    "limite_inferior = Q1 - 1.5 * RIQ\n",
    "limite_superior = Q3 + 1.5 * RIQ\n",
    "\n",
    "#Identifica los outliers:\n",
    "outliers1 = dataToFit < limite_inferior\n",
    "outliers2 = dataToFit > limite_superior\n",
    "dataToFit = np.array(dataToFit)\n",
    "dataToFit = dataToFit.flatten()\n",
    "dataToFit = np.float64(dataToFit)\n",
    "print(dataToFit)\n",
    "print('outliers1  = ', outliers1)\n",
    "print('outliers2  = ', outliers2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar los valores atÃ­picos con NaN en el DataFrame original\n",
    "df_final.loc[df_final['fecha'].isin(outliers['fecha']), 'demanda'] = np.nan\n",
    "\n",
    "# Imprimir el DataFrame con los valores atÃ­picos reemplazados con NaN\n",
    "display(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar los valores por dÃ­a del aÃ±o y calcular el promedio de los valores por dÃ­a del aÃ±o utilizando la funciÃ³n transform\n",
    "promedios_dia = df_final.groupby([df_final['fecha'].dt.month, df_final['fecha'].dt.day])['demanda'].transform(lambda x: x.mean())\n",
    "promedios_dia=promedios_dia.round(decimals=0).astype(int)\n",
    "# Rellenar los valores NaN en la columna de demanda con los promedios calculados utilizando la funciÃ³n fillna\n",
    "df_final['demanda'].fillna(promedios_dia, inplace=True)\n",
    "\n",
    "# Imprimir el DataFrame actualizado\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #convertir la columna 'fecha' a formato de fecha y hora\n",
    "df_final['fecha'] = pd.to_datetime(df_final['fecha'], format=\"'%d-%b-%Y %H:%M:%S'\")\n",
    "# convertir la columna 'fecha' a formato de fecha y hora\n",
    "df_final['fecha'] = pd.to_datetime(df_final['fecha'])\n",
    "# establecer la columna 'fecha' como el Ã­ndice del DataFrame\n",
    "df_final = df_final.set_index('fecha')\n",
    "# Crear una figura y un eje\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Graficar los datos\n",
    "demanda=df_final['demanda'].values\n",
    "ax.plot(df_final.index,demanda )\n",
    "\n",
    "# Establecer la frecuencia y el formato de los valores del eje x\n",
    "ax.set_xticks(df_final.index[::8928])\n",
    "ax.set_xticklabels(df_final.index[::8928], rotation=45)\n",
    "\n",
    "# Agregar etiquetas a los ejes\n",
    "ax.set_xlabel('Fecha')\n",
    "ax.set_ylabel('Demanda')\n",
    "\n",
    "# Agregar un tÃ­tulo al grÃ¡fico\n",
    "ax.set_title('TÃ­tulo del grÃ¡fico')\n",
    "\n",
    "# Mostrar el grÃ¡fico\n",
    "plt.show()\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acotar el DataFrame a un rango de fechas especÃ­fico\n",
    "fecha_inicial = '2007-01-01 00:00:00'\n",
    "fecha_final = '2018-01-01 00:00:00'\n",
    "df_acotado = df_final.loc[(df_final.index >= fecha_inicial) & (df_final.index <= fecha_final)]\n",
    "# Resetear el Ã­ndice y convertir la columna de fechas en una columna del DataFrame\n",
    "df_acotado = df_acotado.reset_index(drop=False)\n",
    "\n",
    "# Renombrar la columna 'index' a un nombre mÃ¡s apropiado\n",
    "df = df.rename(columns={'index': 'fecha'})\n",
    "print(df_acotado)\n",
    "print(df_acotado.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupar por aÃ±o y seleccionar solo las filas del 1 de enero de cada aÃ±o\n",
    "df_1_enero = df_acotado[df_acotado['fecha'].dt.month == 1].groupby(df_acotado['fecha'].dt.year)\n",
    "# Seleccionar las primeras 24 filas de cada grupo\n",
    "df_24h_enero = df_1_enero.head(25)\n",
    "\n",
    "# reset index\n",
    "df_24h_enero.reset_index(drop=True,inplace=True)\n",
    "# Reindexar con nuevo rango de Ã­ndices:\n",
    "df_24h_enero =df_24h_enero.reindex(range(1, len(df_24h_enero)+1  ))\n",
    " #Eliminar las Ãºltimas 2 filas con .iloc[:N]\n",
    "df_24h_enero = df_24h_enero.iloc[:-2]\n",
    "display(df_24h_enero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_24h_enero)\n",
    "# Crear un objeto para graficar los datos\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Graficar los datos\n",
    "arr=df_24h_enero['demanda'].values\n",
    "\n",
    "ax.plot(arr )\n",
    "\n",
    "# Agregar etiquetas a los ejes\n",
    "# Seleccionar las fechas que se mostrarÃ¡n en la etiqueta del eje x\n",
    "# Agregar las etiquetas del eje x\n",
    "ax.set_xlabel('fecha')\n",
    "ax.set_ylabel('Demanda')\n",
    "\n",
    "# Agregar un tÃ­tulo al grÃ¡fico\n",
    "ax.set_title('TÃ­tulo del grÃ¡fico')\n",
    "\n",
    "# Mostrar el grÃ¡fico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_24h_enero.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time period start : {df_24h_enero.fecha.min()}\\nTime period end : {df_24h_enero.fecha.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_24h_enero.columns,df_24h_enero.shape\n",
    "df_24h_enero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting year column to datetime format\n",
    "df_24h_enero['fecha'] = pd.to_datetime(df_24h_enero['fecha'], format = '%Y-%m-%d-%h')\n",
    "df_24h_enero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting year as index for easier manipulations\n",
    "y = df_24h_enero.set_index('fecha')\n",
    "y,y.index,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n",
    "# Crear un objeto para graficar los datos\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Graficar los datos\n",
    "arr=y['demanda'].values\n",
    "\n",
    "ax.plot(arr )\n",
    "\n",
    "# Agregar etiquetas a los ejes\n",
    "# Seleccionar las fechas que se mostrarÃ¡n en la etiqueta del eje x\n",
    "# Agregar las etiquetas del eje x\n",
    "ax.set_xlabel('fecha')\n",
    "ax.set_ylabel('Demanda')\n",
    "\n",
    "# Agregar un tÃ­tulo al grÃ¡fico\n",
    "ax.set_title('TÃ­tulo del grÃ¡fico')\n",
    "\n",
    "# Mostrar el grÃ¡fico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar los datos directamente sin crear fig, ax\n",
    "plt.figure(figsize=(15, 6))  # TamaÃ±o de la figura\n",
    "\n",
    "# Graficar los datos utilizando plot\n",
    "plt.plot(y.index, y['demanda'], label='Demanda', color='blue')\n",
    "\n",
    "# Etiquetas de los ejes\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Demanda')\n",
    "\n",
    "# TÃ­tulo del grÃ¡fico\n",
    "plt.title('TÃ­tulo del grÃ¡fico')\n",
    "\n",
    "# Agregar leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el grÃ¡fico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null values check\n",
    "y.isnull().sum()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Crear una figura y ejes explÃ­citamente\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Density Plot usando Seaborn\n",
    "sns.histplot(y, kde=True, ax=ax)\n",
    "\n",
    "# Etiquetas de los ejes\n",
    "ax.set_xlabel('Fecha')\n",
    "ax.set_ylabel('Demanda')\n",
    "\n",
    "# Mostrar el grÃ¡fico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Crear una figura y ejes explÃ­citamente\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Boxplot usando Seaborn\n",
    "sns.boxplot(x=y.index, y=y['demanda'], ax=ax)\n",
    "\n",
    "# Etiquetas de los ejes\n",
    "ax.set_xlabel('Fecha')\n",
    "ax.set_ylabel('Demanda')\n",
    "\n",
    "# Mostrar el grÃ¡fico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sm.tsa.seasonal_decompose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 18,8\n",
    "decomposition = sm.tsa.seasonal_decompose(y, model='multiplicative',period=24)\n",
    "plt.figure(figsize = (18,8))\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF & PACF Plots\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plot_acf(y['demanda'], ax=plt.gca(), lags = 30)\n",
    "plt.subplot(212)\n",
    "plot_pacf(y['demanda'], ax=plt.gca(), lags = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling Mean & Rolling Standard Deviation\n",
    "rolmean = y.rolling(window = 24).mean() # Calcula con periodo windows la media movil \n",
    "rolstd = y.rolling(window = 24).std() # caclula la desviacino estandar movil segun la  windows \n",
    "\n",
    "plt.figure(figsize = (15,6))\n",
    "orig = plt.plot(y, color = 'blue', label ='Original')\n",
    "mean  = plt.plot(rolmean, color = 'red', label = 'Rolling Mean')\n",
    "std = plt.plot(rolstd, color = 'black', label = 'Rolling Std. Dev.')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Crear una figura y ejes explÃ­citamente\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Graficar la serie temporal original\n",
    "orig = ax.plot(y, color='blue', label='Original')\n",
    "\n",
    "# Graficar la media mÃ³vil\n",
    "mean = ax.plot(rolmean, color='red', label='Rolling Mean')\n",
    "\n",
    "# Graficar la desviaciÃ³n estÃ¡ndar mÃ³vil\n",
    "std = ax.plot(rolstd, color='black', label='Rolling Std. Dev.')\n",
    "\n",
    "# Agregar leyenda\n",
    "ax.legend(loc='best')\n",
    "\n",
    "# Mostrar el grÃ¡fico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating general function to test stationarity of a time series\n",
    "   \n",
    "def test_stationarity(timeseries):\n",
    "    B = timeseries.iloc[:, 0]\n",
    "    B = B.reset_index(drop=True)\n",
    "    # Rolling Mean & Rolling Standard Deviation\n",
    "    rolmean = timeseries.rolling(window = 24).mean()\n",
    "    rolstd = timeseries.rolling(window = 24).std()\n",
    "\n",
    "    plt.figure(figsize = (15,6))\n",
    "    orig = plt.plot(timeseries, color = 'blue', label ='Original')\n",
    "    mean  = plt.plot(rolmean, color = 'red', label = 'Rolling Mean')\n",
    "    std = plt.plot(rolstd, color = 'black', label = 'Rolling Std. Dev.')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.show()\n",
    "    \n",
    "    # Augmented Dicky-Fuller Test\n",
    "    print('-------------Results of Dicky Fuller Test -------------')\n",
    "    dftest = adfuller(timeseries, autolag = 'AIC')\n",
    "    dfoutput = pd.Series(data = dftest[0:4], index = ['Test Statistic : adf', 'p-value : MacKinnon\\'s approximate p-value',\n",
    "                                                     'No. of Lags used', 'No. of observations used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput[f'Critical Value ({key})'] = value\n",
    "    dfoutput['Maximized AIC:'] = dftest[5]\n",
    "    print(dfoutput)\n",
    "    if dftest[1]>0.05 :\n",
    "            print(\"the null hypothesis is fulfilled for no stationary series \")\n",
    "    else:\n",
    "        print(\"the  hypothesis is fulfilled for  stationary series \")\n",
    "    \n",
    "     #! Agree the Levene test\n",
    "    # Divide the data into three equal parts\n",
    "    \n",
    "    if len(B)//2==0 :\n",
    "        part_size = len(B) // 2\n",
    "        seg1 = B[:part_size]\n",
    "        seg2 = B[2*part_size:]\n",
    "            # # Apply the levene test to each pair of segments\n",
    "        resultado_levene_seg1_seg2 = levene(seg1, seg2)\n",
    "    # Apply the levene test to each pair of segments\n",
    "         # # Print the results\n",
    "        print(\"Valor p de la prueba de levene para seg1 y seg2:\", resultado_levene_seg1_seg2.pvalue)\n",
    "        if resultado_levene_seg1_seg2.pvalue < 0.05:\n",
    "            print('La serie no es estacionaria en VARIANZA')\n",
    "        else:\n",
    "            print('La serie es estacionaria en VARIANZA')\n",
    "    else:\n",
    "    # Adjust the parts size if needed to make them approximately equal\n",
    "        part_size = len(B) // 3\n",
    "        # Divide the series into three parts\n",
    "        seg1 = B[:part_size]\n",
    "        seg2 = B[part_size:2*part_size]\n",
    "        seg3 = B[2*part_size:]\n",
    "        print(seg3)\n",
    "        # Apply the levene test to each pair of segments\n",
    "        resultado_levene_seg1_seg2 = levene(seg1, seg2)\n",
    "        resultado_levene_seg2_seg3 = levene(seg2, seg3)\n",
    "        resultado_levene_seg3_seg1 = levene(seg3, seg1)\n",
    "\n",
    "        # Print the results\n",
    "        print(\"Valor p de la prueba de levene para seg1 y seg2:\", resultado_levene_seg1_seg2.pvalue)\n",
    "        print(\"Valor p de la prueba de levene para seg2 y seg3:\", resultado_levene_seg2_seg3.pvalue)\n",
    "        print(\"Valor p de la prueba de levene para seg3 y seg1:\", resultado_levene_seg3_seg1.pvalue)\n",
    "\n",
    "        if resultado_levene_seg1_seg2.pvalue < 0.05 and resultado_levene_seg2_seg3.pvalue < 0.05 and resultado_levene_seg3_seg1.pvalue < 0.05:\n",
    "            print('La serie no es estacionaria en VARIANZA')\n",
    "        else:\n",
    "            print('La serie es estacionaria en VARIANZA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stationarity test of log transformed TS\n",
    "test_stationarity(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting TS data into train and test set for model training and testing\n",
    "\n",
    "\n",
    "train_ts = y.iloc[: 120,]\n",
    "test_ts = y.iloc[120: ,]\n",
    "test_ts.isnull().sum()\n",
    "print(len(y))\n",
    "len(test_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto arima: seleccion basada en AIC\n",
    "# ==============================================================================\n",
    "modelo = auto_arima(\n",
    "            y                 = test_ts,\n",
    "            start_p           = 0,\n",
    "            start_q           = 0,\n",
    "            max_p             = 3,\n",
    "            max_q             = 3,\n",
    "            seasonal          = True,\n",
    "            test              = 'adf',\n",
    "            m                 = 24, # periodicidad de la estacionalidad\n",
    "            d                 = None, # El algoritmo determina 'd'\n",
    "            D                 = None, # El algoritmo determina 'D'\n",
    "            trace             = True,\n",
    "            error_action      = 'ignore',\n",
    "            suppress_warnings = True,\n",
    "            stepwise          = True,\n",
    "            random_state      =42,\n",
    "            n_fits            =15000\n",
    ")\n",
    "print(modelo.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ARIMA(train_ts, order = (1,0,0), seasonal_order=(2,0,0,24))\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ObtÃ©n las predicciones para el conjunto de prueba\n",
    "# predictions = modelo.predict(n_periods=24)\n",
    "predictions_test_=modelo.predict(len(test_ts))\n",
    "# Crea un DataFrame con las fechas y las predicciones\n",
    "predictions_df = pd.DataFrame(index=test_ts.index)\n",
    "predictions_df['Predictions'] = predictions_test_.values  # AsegÃºrate de extraer los valores\n",
    "\n",
    "# AsegÃºrate de que el Ã­ndice del DataFrame sea de tipo datetime\n",
    "predictions_df.index = pd.to_datetime(predictions_df.index)\n",
    "\n",
    "# Imprime el DataFrame con las predicciones\n",
    "print(predictions_df)\n",
    "\n",
    "# Describe el DataFrame con las predicciones\n",
    "predictions_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,6))\n",
    "plt.plot(test_ts, color = 'green', label = 'Log Transformed Original data')\n",
    "plt.plot(predictions_df, color = 'blue', label = 'Predicted values for train dataset')\n",
    "plt.plot(predictions_df, color = 'orange', label = 'Predicted values for test dataset')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Log of no. of passengers')\n",
    "plt.title('ARIMA(3,2,2)(0,1,0)[12] qualitative performance')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

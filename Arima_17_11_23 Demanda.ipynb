{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\milla\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing Basic libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os \n",
    "import re\n",
    "# Importing time series specific libraries\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy.stats import bartlett\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.statespace import sarimax\n",
    "import prophet\n",
    "from prophet import Prophet\n",
    "from scipy.stats import levene\n",
    "# Miscellaneous libararies\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from math import sqrt\n",
    "from random import random\n",
    "\n",
    "# Libaraies for evaluation of model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error, mean_squared_log_error\n",
    "from statsmodels.tsa.arima.model import ARIMAResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     idprov      fecha  dem1  dem2  dem3  dem4  dem5  dem6  dem7  dem8  ...  \\\n",
      "0       IJV 2007-05-01   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "1       IJV 2007-07-01   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "2       IJV 2007-07-27   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "3       IJV 2007-07-28   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "4       IJV 2007-07-30   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
      "...     ...        ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "3915    IJV 2018-04-14  15.0  14.0  13.0  13.0  13.0  13.0  13.0  12.0  ...   \n",
      "3916    IJV 2018-04-15  15.0  14.0  14.0  13.0  13.0  13.0  12.0  12.0  ...   \n",
      "3917    IJV 2018-04-16  14.0  13.0  13.0  13.0  12.0  13.0  12.0  12.0  ...   \n",
      "3918    IJV 2018-04-17  11.0  11.0  10.0  10.0  10.0  10.0  10.0  10.0  ...   \n",
      "3919    IJV 2018-04-18  12.0  11.0  11.0  10.0  10.0  11.0  11.0  11.0  ...   \n",
      "\n",
      "      dem16  dem17  dem18  dem19  dem20  dem21  dem22  dem23  dem24  dem25  \n",
      "0       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "1       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "2       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "3       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "4       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "3915   12.0   12.0   13.0   14.0   15.0   16.0   16.0   16.0   15.0   16.0  \n",
      "3916   12.0   12.0   13.0   14.0   15.0   15.0   16.0   16.0   15.0   16.0  \n",
      "3917   12.0   12.0   12.0   12.0   14.0   14.0   14.0   13.0   12.0   14.0  \n",
      "3918   11.0   11.0   12.0   13.0   14.0   14.0   14.0   13.0   12.0   14.0  \n",
      "3919   13.0   12.0   13.0   13.0   14.0   15.0   15.0   14.0   13.0   15.0  \n",
      "\n",
      "[3920 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "#TODO Cargar los datos de la hoja de calculo en el archivo \"load_IJV.xlsx\"\n",
    "# Obtener la ruta absoluta del script de Python\n",
    "def importar_datos(x):\n",
    "    global df\n",
    "    ruta_script = os.getcwd()\n",
    "    #Nombre del archivo de Excel a cargar\n",
    "    nombre_archivo = x\n",
    "    # Combinar la ruta del script y el nombre del archivo\n",
    "    ruta_archivo = os.path.join(ruta_script, nombre_archivo)\n",
    "    # Cargar los datos del archivo de Excel en un DataFrame de pandas\n",
    "    df = pd.read_excel(ruta_archivo)\n",
    "    # Imprimir el df \n",
    "    return df\n",
    "importar_datos('load_IJV.xlsx')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     idprov      fecha  dem1  dem2  dem3  dem4  dem5  dem6  dem7  dem8  ...  \\\n",
      "159     IJV 2008-01-01   9.0   9.0   8.0   8.0   8.0   9.0   9.0  10.0  ...   \n",
      "160     IJV 2008-01-02   8.0   6.0   8.0   7.0   8.0   8.0   8.0  10.0  ...   \n",
      "161     IJV 2008-01-03   6.0   4.0   5.0   6.0   6.0   5.0  10.0  10.0  ...   \n",
      "162     IJV 2008-01-04   6.0   6.0   7.0   6.0   6.0   8.0  10.0  11.0  ...   \n",
      "163     IJV 2008-01-05   6.0   6.0   6.0   6.0   6.0   8.0   9.0  10.0  ...   \n",
      "...     ...        ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "3807    IJV 2017-12-27  10.0  10.0   9.0   9.0  10.0  10.0  11.0  12.0  ...   \n",
      "3808    IJV 2017-12-28  10.0  10.0  10.0   9.0  10.0  10.0  11.0  12.0  ...   \n",
      "3809    IJV 2017-12-29  11.0  10.0  10.0  10.0  10.0  10.0  11.0  11.0  ...   \n",
      "3810    IJV 2017-12-30  11.0  11.0  10.0  10.0  10.0  10.0  11.0  11.0  ...   \n",
      "3811    IJV 2017-12-31  11.0  10.0  10.0  10.0   9.0  10.0  10.0  11.0  ...   \n",
      "\n",
      "      dem16  dem17  dem18  dem19  dem20  dem21  dem22  dem23  dem24  dem25  \n",
      "159    11.0   12.0   14.0   15.0   12.0   11.0   11.0   10.0   10.0   16.0  \n",
      "160    12.0   15.0   17.0   16.0   11.0    9.0    8.0    7.0    6.0   17.0  \n",
      "161    11.0   15.0   18.0   17.0   12.0   10.0    9.0    7.0    7.0   19.0  \n",
      "162    12.0   14.0   18.0   19.0   13.0   10.0    9.0    7.0    7.0   19.0  \n",
      "163    12.0   11.0   18.0   19.0   14.0   11.0   10.0    8.0    8.0   20.0  \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "3807   12.0   12.0   13.0   16.0   14.0   13.0   12.0   12.0   11.0   16.0  \n",
      "3808   12.0   12.0   15.0   16.0   14.0   13.0   13.0   12.0   11.0   16.0  \n",
      "3809   12.0   13.0   14.0   16.0   14.0   13.0   13.0   12.0   12.0   16.0  \n",
      "3810   11.0   12.0   14.0   15.0   14.0   12.0   12.0   12.0   11.0   15.0  \n",
      "3811   11.0   11.0   12.0   13.0   11.0   10.0   10.0   10.0    9.0   13.0  \n",
      "\n",
      "[3653 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# #Identificar los valores únicos en la columna \"idprov\"\n",
    "# idprov_unique = df[\"idprov\"].unique()\n",
    "\n",
    "# # Verificar si hay valores diferentes a \"IJV\"\n",
    "# if len(idprov_unique) > 1 or idprov_unique[0] != \"'IJV'\":\n",
    "#     # Mostrar los valores diferentes a \"IJV\"\n",
    "#     print(\"Los siguientes valores no son 'IJV':\")\n",
    "#     print(df.loc[df[\"idprov\"] != \"IJV\"])\n",
    "# else:\n",
    "#     # Todos los valores de la columna \"idprov\" son \"IJV\"\n",
    "#     print(\"Todos los valores de la columna 'idprov' son 'IJV'\")\n",
    "#     # Eliminar la columna \"idprov\" del DataFrame\n",
    "#     df = df.drop(\"idprov\", axis=1)\n",
    "# print(df)\n",
    "df = df[df['fecha'] >= '2008-01-01']\n",
    "df = df[df['fecha'] <= '2017-12-31']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     idprov      fecha  dem1  dem2  dem3  dem4  dem5  dem6  dem7  dem8  ...  \\\n",
      "159     IJV 2008-01-01   9.0   9.0   8.0   8.0   8.0   9.0   9.0  10.0  ...   \n",
      "160     IJV 2008-01-02   8.0   6.0   8.0   7.0   8.0   8.0   8.0  10.0  ...   \n",
      "161     IJV 2008-01-03   6.0   4.0   5.0   6.0   6.0   5.0  10.0  10.0  ...   \n",
      "162     IJV 2008-01-04   6.0   6.0   7.0   6.0   6.0   8.0  10.0  11.0  ...   \n",
      "163     IJV 2008-01-05   6.0   6.0   6.0   6.0   6.0   8.0   9.0  10.0  ...   \n",
      "...     ...        ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "3807    IJV 2017-12-27  10.0  10.0   9.0   9.0  10.0  10.0  11.0  12.0  ...   \n",
      "3808    IJV 2017-12-28  10.0  10.0  10.0   9.0  10.0  10.0  11.0  12.0  ...   \n",
      "3809    IJV 2017-12-29  11.0  10.0  10.0  10.0  10.0  10.0  11.0  11.0  ...   \n",
      "3810    IJV 2017-12-30  11.0  11.0  10.0  10.0  10.0  10.0  11.0  11.0  ...   \n",
      "3811    IJV 2017-12-31  11.0  10.0  10.0  10.0   9.0  10.0  10.0  11.0  ...   \n",
      "\n",
      "      dem15  dem16  dem17  dem18  dem19  dem20  dem21  dem22  dem23  dem24  \n",
      "159    11.0   11.0   12.0   14.0   15.0   12.0   11.0   11.0   10.0   10.0  \n",
      "160     8.0   12.0   15.0   17.0   16.0   11.0    9.0    8.0    7.0    6.0  \n",
      "161    11.0   11.0   15.0   18.0   17.0   12.0   10.0    9.0    7.0    7.0  \n",
      "162    11.0   12.0   14.0   18.0   19.0   13.0   10.0    9.0    7.0    7.0  \n",
      "163    11.0   12.0   11.0   18.0   19.0   14.0   11.0   10.0    8.0    8.0  \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "3807   12.0   12.0   12.0   13.0   16.0   14.0   13.0   12.0   12.0   11.0  \n",
      "3808   12.0   12.0   12.0   15.0   16.0   14.0   13.0   13.0   12.0   11.0  \n",
      "3809   12.0   12.0   13.0   14.0   16.0   14.0   13.0   13.0   12.0   12.0  \n",
      "3810   11.0   11.0   12.0   14.0   15.0   14.0   12.0   12.0   12.0   11.0  \n",
      "3811   11.0   11.0   11.0   12.0   13.0   11.0   10.0   10.0   10.0    9.0  \n",
      "\n",
      "[3653 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# eliminar la columna 25 porque me da el maximo valor solamente \n",
    "df = df.drop('dem25', axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  idprov      fecha  dem1  dem2  dem3  dem4  dem5  dem6  dem7  dem8  ...  \\\n",
      "1    IJV 2008-01-01   9.0   9.0   8.0   8.0   8.0   9.0   9.0  10.0  ...   \n",
      "2    IJV 2008-01-02   8.0   6.0   8.0   7.0   8.0   8.0   8.0  10.0  ...   \n",
      "3    IJV 2008-01-03   6.0   4.0   5.0   6.0   6.0   5.0  10.0  10.0  ...   \n",
      "4    IJV 2008-01-04   6.0   6.0   7.0   6.0   6.0   8.0  10.0  11.0  ...   \n",
      "5    IJV 2008-01-05   6.0   6.0   6.0   6.0   6.0   8.0   9.0  10.0  ...   \n",
      "\n",
      "   dem15  dem16  dem17  dem18  dem19  dem20  dem21  dem22  dem23  dem24  \n",
      "1   11.0   11.0   12.0   14.0   15.0   12.0   11.0   11.0   10.0   10.0  \n",
      "2    8.0   12.0   15.0   17.0   16.0   11.0    9.0    8.0    7.0    6.0  \n",
      "3   11.0   11.0   15.0   18.0   17.0   12.0   10.0    9.0    7.0    7.0  \n",
      "4   11.0   12.0   14.0   18.0   19.0   13.0   10.0    9.0    7.0    7.0  \n",
      "5   11.0   12.0   11.0   18.0   19.0   14.0   11.0   10.0    8.0    8.0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#  #convertir la columna 'fecha' a formato de fecha y hora\n",
    "# df['fecha'] = pd.to_datetime(df['fecha'], format=\"'%d-%b-%Y %H:%M:%S'\")\n",
    "# # convertir la columna 'fecha' a formato de fecha y hora\n",
    "# df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "# # establecer la columna 'fecha' como el índice del DataFrame\n",
    "# df = df.set_index('fecha')\n",
    "# # utilizar resample con una frecuencia de 1 hora para agregar una fila por cada hora del día\n",
    "# df_resampled = df.resample('1H').asfreq()\n",
    "# display(df_resampled)\n",
    "# restaring the index\n",
    "df.index = np.arange(1, len(df) + 1, 1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengthBefore = 3653\n",
      "[60, 1521, 2982]\n",
      "lengthAfter = 3650\n"
     ]
    }
   ],
   "source": [
    "# def sort_columns(col):\n",
    "#     return int(re.findall(r'\\d+', col)[0])\n",
    "\n",
    "# # ordenar las columnas de demanda por su número\n",
    "# cols_dem = sorted([col for col in df_resampled.columns if 'dem' in col], key=sort_columns)\n",
    "\n",
    "\n",
    "# # apilar las columnas de demanda en una sola columna\n",
    "# df_melted = df_resampled[cols_dem].reset_index().melt(id_vars='fecha', var_name='hora', value_name='demanda')\n",
    "\n",
    "# # eliminar las filas con NaN en la columna de demanda\n",
    "# df_clean = df_melted.dropna(subset=['demanda'])\n",
    "\n",
    "# # convertir la columna hora en una categoría ordenada\n",
    "# df_clean['hora'] = pd.Categorical(df_clean['hora'], categories=[f'dem{i}' for i in range(0,25)], ordered=True)\n",
    "\n",
    "\n",
    "# # ordenar el DataFrame por fecha y hora\n",
    "# df_final = df_clean.sort_values(['fecha', 'hora'])\n",
    "\n",
    "\n",
    "\n",
    "# # resetear el índice del DataFrame\n",
    "# df_final = df_final.reset_index(drop=True)\n",
    "\n",
    "# df_final = df_final.drop('hora', axis=1)\n",
    "\n",
    "# #TODO ponerle hora a cada una de las fechas -------------------------------------------------------------------------------------\n",
    "# # convertir la columna fecha en un objeto datetime\n",
    "# df_final['fecha'] = pd.to_datetime(df_final['fecha'], format='%d-%b-%Y %H:%M:%S')\n",
    "\n",
    "# last_day = None\n",
    "# # Organizar el datatime para agregarle una hora a cada datatime cada 24 horas\n",
    "# for i in range(len(df_final)):\n",
    "#     # Verificar si se debe reiniciar la suma\n",
    "#     if last_day is None or df_final.loc[i, 'fecha'].day != last_day:\n",
    "#         last_day = df_final.loc[i, 'fecha'].day\n",
    "#         hours_to_add = 1\n",
    "#     else:\n",
    "#         hours_to_add += 1\n",
    "        \n",
    "#     # Agregar la cantidad de horas correspondiente\n",
    "#     df_final.loc[i, 'fecha'] += pd.DateOffset(hours=hours_to_add)\n",
    "\n",
    "# display( df_final) \n",
    "# removing February 29\n",
    "print(\"lengthBefore =\", len(df)) # checking\n",
    "idx_1 = df[df[\"fecha\"] == '2008-02-29']\n",
    "idx_2 = df[df[\"fecha\"] == '2012-02-29']\n",
    "idx_3 = df[df[\"fecha\"] == '2016-02-29']\n",
    "toRemove = [idx_1.index.item(), idx_2.index.item(), idx_3.index.item()]\n",
    "print(toRemove)\n",
    "df = df.drop(toRemove)\n",
    "print(\"lengthAfter =\", len(df)) # checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     idprov      fecha  dem1  dem2  dem3  dem4  dem5  dem6  dem7  dem8  ...  \\\n",
      "1       IJV 2008-01-01   9.0   9.0   8.0   8.0   8.0   9.0   9.0  10.0  ...   \n",
      "367     IJV 2009-01-01   8.0   8.0   8.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "732     IJV 2010-01-01   8.0   7.0   7.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "1097    IJV 2011-01-01   7.0   6.0   6.0   6.0   6.0   6.0   6.0   8.0  ...   \n",
      "1462    IJV 2012-01-01   8.0   7.0   6.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "1828    IJV 2013-01-01   8.0   8.0   8.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "2193    IJV 2014-01-01  11.0  10.0  10.0  10.0   9.0  10.0  10.0  10.0  ...   \n",
      "2558    IJV 2015-01-01  10.0  10.0   9.0   9.0   9.0   9.0   9.0  10.0  ...   \n",
      "2923    IJV 2016-01-01  12.0  12.0  11.0  11.0  11.0  11.0  10.0  11.0  ...   \n",
      "3289    IJV 2017-01-01  10.0  10.0  10.0   9.0   9.0   9.0   9.0  10.0  ...   \n",
      "\n",
      "      dem15  dem16  dem17  dem18  dem19  dem20  dem21  dem22  dem23  dem24  \n",
      "1      11.0   11.0   12.0   14.0   15.0   12.0   11.0   11.0   10.0   10.0  \n",
      "367     9.0   10.0   11.0   13.0   13.0   11.0   10.0    9.0    8.0    8.0  \n",
      "732     9.0    9.0   11.0   12.0   14.0   12.0   10.0    9.0    8.0    8.0  \n",
      "1097    9.0    9.0   10.0   13.0   13.0   11.0    9.0    8.0    8.0    7.0  \n",
      "1462    9.0    9.0   10.0   13.0   14.0   11.0   10.0    9.0    8.0    8.0  \n",
      "1828    9.0    9.0   11.0   13.0   14.0   12.0   10.0   10.0    9.0    8.0  \n",
      "2193    9.0   10.0   11.0   13.0   14.0   13.0   12.0   12.0   11.0   10.0  \n",
      "2558    9.0   10.0   11.0   10.0   14.0   12.0   12.0   11.0   11.0   10.0  \n",
      "2923   11.0   11.0   11.0   13.0   14.0   13.0   13.0   13.0   12.0   11.0  \n",
      "3289   10.0   10.0   11.0   12.0   14.0   12.0   12.0   12.0   12.0   11.0  \n",
      "\n",
      "[10 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# # Seleccionar las filas que no tienen fechas del 29 de febrero\n",
    "# df_final = df_final.loc[(df_final['fecha'].dt.day != 29) | (df_final['fecha'].dt.month != 2)]\n",
    "\n",
    "# # Imprimir el nuevo DataFrame sin las filas del 29 de febrero\n",
    "# print(df_final)\n",
    "# filtering data needed\n",
    "dfFiltered = df[df['fecha'].dt.strftime('%m-%d') == '01-01']\n",
    "print(dfFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   idprov      fecha  dem1  dem2  dem3  dem4  dem5  dem6  dem7  dem8  ...  \\\n",
      "1     IJV 2008-01-01   9.0   9.0   8.0   8.0   8.0   9.0   9.0  10.0  ...   \n",
      "2     IJV 2009-01-01   8.0   8.0   8.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "3     IJV 2010-01-01   8.0   7.0   7.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "4     IJV 2011-01-01   7.0   6.0   6.0   6.0   6.0   6.0   6.0   8.0  ...   \n",
      "5     IJV 2012-01-01   8.0   7.0   6.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "6     IJV 2013-01-01   8.0   8.0   8.0   7.0   7.0   7.0   7.0   8.0  ...   \n",
      "7     IJV 2014-01-01  11.0  10.0  10.0  10.0   9.0  10.0  10.0  10.0  ...   \n",
      "8     IJV 2015-01-01  10.0  10.0   9.0   9.0   9.0   9.0   9.0  10.0  ...   \n",
      "9     IJV 2016-01-01  12.0  12.0  11.0  11.0  11.0  11.0  10.0  11.0  ...   \n",
      "10    IJV 2017-01-01  10.0  10.0  10.0   9.0   9.0   9.0   9.0  10.0  ...   \n",
      "\n",
      "    dem15  dem16  dem17  dem18  dem19  dem20  dem21  dem22  dem23  dem24  \n",
      "1    11.0   11.0   12.0   14.0   15.0   12.0   11.0   11.0   10.0   10.0  \n",
      "2     9.0   10.0   11.0   13.0   13.0   11.0   10.0    9.0    8.0    8.0  \n",
      "3     9.0    9.0   11.0   12.0   14.0   12.0   10.0    9.0    8.0    8.0  \n",
      "4     9.0    9.0   10.0   13.0   13.0   11.0    9.0    8.0    8.0    7.0  \n",
      "5     9.0    9.0   10.0   13.0   14.0   11.0   10.0    9.0    8.0    8.0  \n",
      "6     9.0    9.0   11.0   13.0   14.0   12.0   10.0   10.0    9.0    8.0  \n",
      "7     9.0   10.0   11.0   13.0   14.0   13.0   12.0   12.0   11.0   10.0  \n",
      "8     9.0   10.0   11.0   10.0   14.0   12.0   12.0   11.0   11.0   10.0  \n",
      "9    11.0   11.0   11.0   13.0   14.0   13.0   13.0   13.0   12.0   11.0  \n",
      "10   10.0   10.0   11.0   12.0   14.0   12.0   12.0   12.0   12.0   11.0  \n",
      "\n",
      "[10 rows x 26 columns]\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "[ 9.  9.  8.  8.  8.  9.  9. 10. 11. 12. 12. 12. 11. 10. 11. 11. 12. 14.\n",
      " 15. 12. 11. 11. 10. 10.  8.  8.  8.  7.  7.  7.  7.  8. 10. 10. 10. 11.\n",
      " 10.  9.  9. 10. 11. 13. 13. 11. 10.  9.  8.  8.  8.  7.  7.  7.  7.  7.\n",
      "  7.  8.  9.  9. 10. 10.  9.  9.  9.  9. 11. 12. 14. 12. 10.  9.  8.  8.\n",
      "  7.  6.  6.  6.  6.  6.  6.  8.  9. 10. 10. 10.  9.  8.  9.  9. 10. 13.\n",
      " 13. 11.  9.  8.  8.  7.  8.  7.  6.  7.  7.  7.  7.  8.  9.  9. 10. 10.\n",
      "  9.  9.  9.  9. 10. 13. 14. 11. 10.  9.  8.  8.  8.  8.  8.  7.  7.  7.\n",
      "  7.  8.  9. 10. 10. 10. 10.  9.  9.  9. 11. 13. 14. 12. 10. 10.  9.  8.\n",
      " 11. 10. 10. 10.  9. 10. 10. 10. 10. 10. 11. 11. 10. 10.  9. 10. 11. 13.\n",
      " 14. 13. 12. 12. 11. 10. 10. 10.  9.  9.  9.  9.  9. 10. 10. 10. 10. 10.\n",
      " 10.  9.  9. 10. 11. 10. 14. 12. 12. 11. 11. 10. 12. 12. 11. 11. 11. 11.\n",
      " 10. 11. 12. 12. 12. 12. 11. 11. 11. 11. 11. 13. 14. 13. 13. 13. 12. 11.\n",
      " 10. 10. 10.  9.  9.  9.  9. 10. 10. 10. 11. 11. 11.  9. 10. 10. 11. 12.\n",
      " 14. 12. 12. 12. 12. 11.]\n"
     ]
    }
   ],
   "source": [
    "# # TODO calcular los valores atipicos de los datos a partir del cálculo basado en el rango intercuartílico (RIQ)\n",
    "df_final = dfFiltered\n",
    "# restaring the index\n",
    "df_final.index = np.arange(1, len(df_final) + 1, 1)\n",
    "print(df_final)\n",
    "\n",
    "# reshape the data\n",
    "dataToFit = []\n",
    "for k in range(1, 11):\n",
    "    print(k)\n",
    "    data = df_final.loc[k,['dem1', 'dem2', 'dem3', 'dem4', 'dem5', 'dem6', 'dem7', 'dem8', 'dem9', 'dem10', 'dem11', 'dem12', 'dem13', 'dem14', 'dem15', 'dem16', 'dem17', 'dem18', 'dem19', 'dem20', 'dem21', 'dem22', 'dem23', 'dem24']]\n",
    "    data = np.array(data)    \n",
    "    dataToFit.append(data)\n",
    "    \n",
    "    #Calcula el rango intercuartílico (RIQ):\n",
    "Q1 = np.percentile(dataToFit, 25)\n",
    "Q3 = np.percentile(dataToFit, 75)\n",
    "RIQ = Q3 - Q1\n",
    "\n",
    "#Define los límites inferior y superior para detectar outliers:\n",
    "limite_inferior = Q1 - 1.5 * RIQ\n",
    "limite_superior = Q3 + 1.5 * RIQ\n",
    "\n",
    "#Identifica los outliers:\n",
    "outliers1 = dataToFit < limite_inferior\n",
    "outliers2 = dataToFit > limite_superior\n",
    "dataToFit = np.array(dataToFit)\n",
    "dataToFit = dataToFit.flatten()\n",
    "dataToFit = np.float64(dataToFit)\n",
    "print(dataToFit)\n",
    "print('outliers1  = ', outliers1)\n",
    "print('outliers2  = ', outliers2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar los valores atípicos con NaN en el DataFrame original\n",
    "df_final.loc[df_final['fecha'].isin(outliers['fecha']), 'demanda'] = np.nan\n",
    "\n",
    "# Imprimir el DataFrame con los valores atípicos reemplazados con NaN\n",
    "display(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar los valores por día del año y calcular el promedio de los valores por día del año utilizando la función transform\n",
    "promedios_dia = df_final.groupby([df_final['fecha'].dt.month, df_final['fecha'].dt.day])['demanda'].transform(lambda x: x.mean())\n",
    "promedios_dia=promedios_dia.round(decimals=0).astype(int)\n",
    "# Rellenar los valores NaN en la columna de demanda con los promedios calculados utilizando la función fillna\n",
    "df_final['demanda'].fillna(promedios_dia, inplace=True)\n",
    "\n",
    "# Imprimir el DataFrame actualizado\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #convertir la columna 'fecha' a formato de fecha y hora\n",
    "df_final['fecha'] = pd.to_datetime(df_final['fecha'], format=\"'%d-%b-%Y %H:%M:%S'\")\n",
    "# convertir la columna 'fecha' a formato de fecha y hora\n",
    "df_final['fecha'] = pd.to_datetime(df_final['fecha'])\n",
    "# establecer la columna 'fecha' como el índice del DataFrame\n",
    "df_final = df_final.set_index('fecha')\n",
    "# Crear una figura y un eje\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Graficar los datos\n",
    "demanda=df_final['demanda'].values\n",
    "ax.plot(df_final.index,demanda )\n",
    "\n",
    "# Establecer la frecuencia y el formato de los valores del eje x\n",
    "ax.set_xticks(df_final.index[::8928])\n",
    "ax.set_xticklabels(df_final.index[::8928], rotation=45)\n",
    "\n",
    "# Agregar etiquetas a los ejes\n",
    "ax.set_xlabel('Fecha')\n",
    "ax.set_ylabel('Demanda')\n",
    "\n",
    "# Agregar un título al gráfico\n",
    "ax.set_title('Título del gráfico')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acotar el DataFrame a un rango de fechas específico\n",
    "fecha_inicial = '2007-01-01 00:00:00'\n",
    "fecha_final = '2018-01-01 00:00:00'\n",
    "df_acotado = df_final.loc[(df_final.index >= fecha_inicial) & (df_final.index <= fecha_final)]\n",
    "# Resetear el índice y convertir la columna de fechas en una columna del DataFrame\n",
    "df_acotado = df_acotado.reset_index(drop=False)\n",
    "\n",
    "# Renombrar la columna 'index' a un nombre más apropiado\n",
    "df = df.rename(columns={'index': 'fecha'})\n",
    "print(df_acotado)\n",
    "print(df_acotado.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupar por año y seleccionar solo las filas del 1 de enero de cada año\n",
    "df_1_enero = df_acotado[df_acotado['fecha'].dt.month == 1].groupby(df_acotado['fecha'].dt.year)\n",
    "# Seleccionar las primeras 24 filas de cada grupo\n",
    "df_24h_enero = df_1_enero.head(25)\n",
    "\n",
    "# reset index\n",
    "df_24h_enero.reset_index(drop=True,inplace=True)\n",
    "# Reindexar con nuevo rango de índices:\n",
    "df_24h_enero =df_24h_enero.reindex(range(1, len(df_24h_enero)+1  ))\n",
    " #Eliminar las últimas 2 filas con .iloc[:N]\n",
    "df_24h_enero = df_24h_enero.iloc[:-2]\n",
    "display(df_24h_enero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_24h_enero)\n",
    "# Crear un objeto para graficar los datos\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Graficar los datos\n",
    "arr=df_24h_enero['demanda'].values\n",
    "\n",
    "ax.plot(arr )\n",
    "\n",
    "# Agregar etiquetas a los ejes\n",
    "# Seleccionar las fechas que se mostrarán en la etiqueta del eje x\n",
    "# Agregar las etiquetas del eje x\n",
    "ax.set_xlabel('fecha')\n",
    "ax.set_ylabel('Demanda')\n",
    "\n",
    "# Agregar un título al gráfico\n",
    "ax.set_title('Título del gráfico')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_24h_enero.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Time period start : {df_24h_enero.fecha.min()}\\nTime period end : {df_24h_enero.fecha.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_24h_enero.columns,df_24h_enero.shape\n",
    "df_24h_enero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting year column to datetime format\n",
    "df_24h_enero['fecha'] = pd.to_datetime(df_24h_enero['fecha'], format = '%Y-%m-%d-%h')\n",
    "df_24h_enero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting year as index for easier manipulations\n",
    "y = df_24h_enero.set_index('fecha')\n",
    "y,y.index,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n",
    "# Crear un objeto para graficar los datos\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Graficar los datos\n",
    "arr=y['demanda'].values\n",
    "\n",
    "ax.plot(arr )\n",
    "\n",
    "# Agregar etiquetas a los ejes\n",
    "# Seleccionar las fechas que se mostrarán en la etiqueta del eje x\n",
    "# Agregar las etiquetas del eje x\n",
    "ax.set_xlabel('fecha')\n",
    "ax.set_ylabel('Demanda')\n",
    "\n",
    "# Agregar un título al gráfico\n",
    "ax.set_title('Título del gráfico')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar los datos directamente sin crear fig, ax\n",
    "plt.figure(figsize=(15, 6))  # Tamaño de la figura\n",
    "\n",
    "# Graficar los datos utilizando plot\n",
    "plt.plot(y.index, y['demanda'], label='Demanda', color='blue')\n",
    "\n",
    "# Etiquetas de los ejes\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Demanda')\n",
    "\n",
    "# Título del gráfico\n",
    "plt.title('Título del gráfico')\n",
    "\n",
    "# Agregar leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null values check\n",
    "y.isnull().sum()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Crear una figura y ejes explícitamente\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Density Plot usando Seaborn\n",
    "sns.histplot(y, kde=True, ax=ax)\n",
    "\n",
    "# Etiquetas de los ejes\n",
    "ax.set_xlabel('Fecha')\n",
    "ax.set_ylabel('Demanda')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Crear una figura y ejes explícitamente\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Boxplot usando Seaborn\n",
    "sns.boxplot(x=y.index, y=y['demanda'], ax=ax)\n",
    "\n",
    "# Etiquetas de los ejes\n",
    "ax.set_xlabel('Fecha')\n",
    "ax.set_ylabel('Demanda')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sm.tsa.seasonal_decompose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 18,8\n",
    "decomposition = sm.tsa.seasonal_decompose(y, model='multiplicative',period=24)\n",
    "plt.figure(figsize = (18,8))\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF & PACF Plots\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plot_acf(y['demanda'], ax=plt.gca(), lags = 30)\n",
    "plt.subplot(212)\n",
    "plot_pacf(y['demanda'], ax=plt.gca(), lags = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling Mean & Rolling Standard Deviation\n",
    "rolmean = y.rolling(window = 24).mean() # Calcula con periodo windows la media movil \n",
    "rolstd = y.rolling(window = 24).std() # caclula la desviacino estandar movil segun la  windows \n",
    "\n",
    "plt.figure(figsize = (15,6))\n",
    "orig = plt.plot(y, color = 'blue', label ='Original')\n",
    "mean  = plt.plot(rolmean, color = 'red', label = 'Rolling Mean')\n",
    "std = plt.plot(rolstd, color = 'black', label = 'Rolling Std. Dev.')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Crear una figura y ejes explícitamente\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Graficar la serie temporal original\n",
    "orig = ax.plot(y, color='blue', label='Original')\n",
    "\n",
    "# Graficar la media móvil\n",
    "mean = ax.plot(rolmean, color='red', label='Rolling Mean')\n",
    "\n",
    "# Graficar la desviación estándar móvil\n",
    "std = ax.plot(rolstd, color='black', label='Rolling Std. Dev.')\n",
    "\n",
    "# Agregar leyenda\n",
    "ax.legend(loc='best')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating general function to test stationarity of a time series\n",
    "   \n",
    "def test_stationarity(timeseries):\n",
    "    B = timeseries.iloc[:, 0]\n",
    "    B = B.reset_index(drop=True)\n",
    "    # Rolling Mean & Rolling Standard Deviation\n",
    "    rolmean = timeseries.rolling(window = 24).mean()\n",
    "    rolstd = timeseries.rolling(window = 24).std()\n",
    "\n",
    "    plt.figure(figsize = (15,6))\n",
    "    orig = plt.plot(timeseries, color = 'blue', label ='Original')\n",
    "    mean  = plt.plot(rolmean, color = 'red', label = 'Rolling Mean')\n",
    "    std = plt.plot(rolstd, color = 'black', label = 'Rolling Std. Dev.')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.show()\n",
    "    \n",
    "    # Augmented Dicky-Fuller Test\n",
    "    print('-------------Results of Dicky Fuller Test -------------')\n",
    "    dftest = adfuller(timeseries, autolag = 'AIC')\n",
    "    dfoutput = pd.Series(data = dftest[0:4], index = ['Test Statistic : adf', 'p-value : MacKinnon\\'s approximate p-value',\n",
    "                                                     'No. of Lags used', 'No. of observations used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput[f'Critical Value ({key})'] = value\n",
    "    dfoutput['Maximized AIC:'] = dftest[5]\n",
    "    print(dfoutput)\n",
    "    if dftest[1]>0.05 :\n",
    "            print(\"the null hypothesis is fulfilled for no stationary series \")\n",
    "    else:\n",
    "        print(\"the  hypothesis is fulfilled for  stationary series \")\n",
    "    \n",
    "     #! Agree the Levene test\n",
    "    # Divide the data into three equal parts\n",
    "    \n",
    "    if len(B)//2==0 :\n",
    "        part_size = len(B) // 2\n",
    "        seg1 = B[:part_size]\n",
    "        seg2 = B[2*part_size:]\n",
    "            # # Apply the levene test to each pair of segments\n",
    "        resultado_levene_seg1_seg2 = levene(seg1, seg2)\n",
    "    # Apply the levene test to each pair of segments\n",
    "         # # Print the results\n",
    "        print(\"Valor p de la prueba de levene para seg1 y seg2:\", resultado_levene_seg1_seg2.pvalue)\n",
    "        if resultado_levene_seg1_seg2.pvalue < 0.05:\n",
    "            print('La serie no es estacionaria en VARIANZA')\n",
    "        else:\n",
    "            print('La serie es estacionaria en VARIANZA')\n",
    "    else:\n",
    "    # Adjust the parts size if needed to make them approximately equal\n",
    "        part_size = len(B) // 3\n",
    "        # Divide the series into three parts\n",
    "        seg1 = B[:part_size]\n",
    "        seg2 = B[part_size:2*part_size]\n",
    "        seg3 = B[2*part_size:]\n",
    "        print(seg3)\n",
    "        # Apply the levene test to each pair of segments\n",
    "        resultado_levene_seg1_seg2 = levene(seg1, seg2)\n",
    "        resultado_levene_seg2_seg3 = levene(seg2, seg3)\n",
    "        resultado_levene_seg3_seg1 = levene(seg3, seg1)\n",
    "\n",
    "        # Print the results\n",
    "        print(\"Valor p de la prueba de levene para seg1 y seg2:\", resultado_levene_seg1_seg2.pvalue)\n",
    "        print(\"Valor p de la prueba de levene para seg2 y seg3:\", resultado_levene_seg2_seg3.pvalue)\n",
    "        print(\"Valor p de la prueba de levene para seg3 y seg1:\", resultado_levene_seg3_seg1.pvalue)\n",
    "\n",
    "        if resultado_levene_seg1_seg2.pvalue < 0.05 and resultado_levene_seg2_seg3.pvalue < 0.05 and resultado_levene_seg3_seg1.pvalue < 0.05:\n",
    "            print('La serie no es estacionaria en VARIANZA')\n",
    "        else:\n",
    "            print('La serie es estacionaria en VARIANZA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stationarity test of log transformed TS\n",
    "test_stationarity(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting TS data into train and test set for model training and testing\n",
    "\n",
    "\n",
    "train_ts = y.iloc[: 120,]\n",
    "test_ts = y.iloc[120: ,]\n",
    "test_ts.isnull().sum()\n",
    "print(len(y))\n",
    "len(test_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto arima: seleccion basada en AIC\n",
    "# ==============================================================================\n",
    "modelo = auto_arima(\n",
    "            y                 = test_ts,\n",
    "            start_p           = 0,\n",
    "            start_q           = 0,\n",
    "            max_p             = 3,\n",
    "            max_q             = 3,\n",
    "            seasonal          = True,\n",
    "            test              = 'adf',\n",
    "            m                 = 24, # periodicidad de la estacionalidad\n",
    "            d                 = None, # El algoritmo determina 'd'\n",
    "            D                 = None, # El algoritmo determina 'D'\n",
    "            trace             = True,\n",
    "            error_action      = 'ignore',\n",
    "            suppress_warnings = True,\n",
    "            stepwise          = True,\n",
    "            random_state      =42,\n",
    "            n_fits            =15000\n",
    ")\n",
    "print(modelo.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ARIMA(train_ts, order = (1,0,0), seasonal_order=(2,0,0,24))\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtén las predicciones para el conjunto de prueba\n",
    "# predictions = modelo.predict(n_periods=24)\n",
    "predictions_test_=modelo.predict(len(test_ts))\n",
    "# Crea un DataFrame con las fechas y las predicciones\n",
    "predictions_df = pd.DataFrame(index=test_ts.index)\n",
    "predictions_df['Predictions'] = predictions_test_.values  # Asegúrate de extraer los valores\n",
    "\n",
    "# Asegúrate de que el índice del DataFrame sea de tipo datetime\n",
    "predictions_df.index = pd.to_datetime(predictions_df.index)\n",
    "\n",
    "# Imprime el DataFrame con las predicciones\n",
    "print(predictions_df)\n",
    "\n",
    "# Describe el DataFrame con las predicciones\n",
    "predictions_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,6))\n",
    "plt.plot(test_ts, color = 'green', label = 'Log Transformed Original data')\n",
    "plt.plot(predictions_df, color = 'blue', label = 'Predicted values for train dataset')\n",
    "plt.plot(predictions_df, color = 'orange', label = 'Predicted values for test dataset')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Log of no. of passengers')\n",
    "plt.title('ARIMA(3,2,2)(0,1,0)[12] qualitative performance')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
